{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\n",
    "    \"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n",
    "\n",
    "def get_paths(filename, old_dir, new_dir, new_ext):\n",
    "    old_path = os.path.join(old_dir, filename)\n",
    "    basename, ext = os.path.splitext(filename)\n",
    "    if new_ext is not None:\n",
    "        new_filename = basename + new_ext\n",
    "    else:\n",
    "        new_filename = filename\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    return old_path, new_path\n",
    "\n",
    "def dir_map(old_dir: str, new_dir: str, func, old_ext: str, new_ext: str = None, n_jobs: int = -1) -> None:\n",
    "    \"\"\"\n",
    "    Maps the files in the input directory `old_dir` with the extension `old_ext` to the output directory `new_dir`\n",
    "    using the provided function `func`. If `new_ext` is specified, the output files will have the extension `new_ext`;\n",
    "    otherwise, they will have the same extension as the input files. If `new_dir` does not exist, it will be created.\n",
    "\n",
    "    Args:\n",
    "        old_dir (str): The input directory containing the files to be processed.\n",
    "        new_dir (str): The output directory where the processed files will be written.\n",
    "        func (callable): A function that takes the path to an input file and the path to an output file as arguments,\n",
    "            reads the contents of the input file, processes the contents, and writes the result to the output file.\n",
    "        old_ext (str): The extension of the input files to be processed.\n",
    "        new_ext (str, optional): The extension to use for the output files. If not specified, the output files will\n",
    "            have the same extension as the input files.\n",
    "        n_jobs (int, optional): The number of parallel jobs to use. If -1, the number of jobs is set to the number\n",
    "            of available CPU cores.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "    files = [filename for filename in os.listdir(old_dir) if filename.endswith(old_ext)]\n",
    "\n",
    "    with tqdm_joblib(tqdm(desc=\"Processing files\", total=len(files))):\n",
    "        joblib.Parallel(n_jobs=n_jobs, backend='multiprocessing')(joblib.delayed(func)(*get_paths(filename, old_dir, new_dir, new_ext)) for filename in files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def extract_RGB(input_file, output_file=None):\n",
    "    \"\"\"Extracts the first 3 channels of an input (16Bit) geotiff file and saves them to a PNG or JPEG file.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): The path to the input geotiff file.\n",
    "        output_file (str, optional): The path to the output file. If None, the output file will be created in the same\n",
    "            directory as the input file with the same base name and the appropriate extension based on the image format.\n",
    "            Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the specified output format is not supported.\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore', message='Dataset has no geotransform')\n",
    "    warnings.filterwarnings('ignore', message='All-NaN slice encountered')\n",
    "    # Open the input file and read its metadata\n",
    "    with rasterio.open(input_file) as src:\n",
    "        # height, width = src.shape\n",
    "        # count = src.count\n",
    "        # dtype = src.dtypes[0]\n",
    "\n",
    "        # Read the first 3 channels of the input file\n",
    "        data = src.read(indexes=[1, 2, 3])\n",
    "    data_float = data.astype('float32')\n",
    "    data_float[(data_float == 0) | (data_float == 65535.0)] = np.nan\n",
    "    # NoData percentage threshold\n",
    "    if np.count_nonzero(np.isnan(data_float)) / data_float.size > 0.2 :\n",
    "        return\n",
    "    # Calculate the percentile range of each channel\n",
    "    min_vals, max_vals = [], []\n",
    "    for channel in range(data_float.shape[0]):\n",
    "        \n",
    "        min_val, max_val = np.nanpercentile(data_float[channel], (2, 98))\n",
    "        min_vals.append(min_val)\n",
    "        max_vals.append(max_val)\n",
    "\n",
    "    # Min-max stretch each channel to enhance contrast and handle out-of-range values\n",
    "    for channel in range(data.shape[0]):\n",
    "        # Clip the pixel values below the 2nd percentile to the 2nd percentile value\n",
    "        data[channel] = np.clip(data[channel], min_vals[channel], None)\n",
    "        # Clip the pixel values above the 98th percentile to the 98th percentile value\n",
    "        data[channel] = np.clip(data[channel], None, max_vals[channel])\n",
    "        # Min-max stretch the pixel values to the range [0, 255]\n",
    "        if (max_vals[channel] - min_vals[channel]) == 0:\n",
    "            return\n",
    "        data[channel] = (data[channel] - min_vals[channel]) / (max_vals[channel] - min_vals[channel]) * 255\n",
    "\n",
    "    # Cast the data to uint8\n",
    "    data = data.astype(np.uint8)\n",
    "\n",
    "    # Create a PIL image from the data\n",
    "    image = Image.fromarray(np.transpose(data, [1, 2, 0]))\n",
    "\n",
    "    # Set the output file path\n",
    "    if output_file is None:\n",
    "        output_file = os.path.splitext(input_file)[0] + '.png'\n",
    "    else:\n",
    "        output_file = os.path.splitext(output_file)[0] + '.png'\n",
    "\n",
    "    # Determine the image format based on the file extension\n",
    "    format = os.path.splitext(output_file)[1][1:].lower()\n",
    "    if format not in ['png', 'jpg']:\n",
    "        raise ValueError(f\"Unsupported output format '{format}'. Supported formats are 'png' and 'jpg'.\")\n",
    "\n",
    "    # Save the image to the output file\n",
    "    if format == 'png':\n",
    "        image.save(output_file)\n",
    "    elif format == 'jpg':\n",
    "        image.convert('RGB').save(output_file)\n",
    "!rm ./Dataset/Guochan_HR/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 2813/2813 [00:27<00:00, 100.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2462\n"
     ]
    }
   ],
   "source": [
    "!rm -f ./Dataset/Guochan_HR/*.png\n",
    "dir_map(\"../超分重建数据/高分_切片去坐标/image_chips\", \"./Dataset/Guochan_HR\", extract_RGB, old_ext='tif')\n",
    "!ls -al ./Dataset/Guochan_HR/*.png | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "scale_factor = 1/2\n",
    "def raster_rescale(in_file, out_file, scale_factor):\n",
    "\n",
    "    with rasterio.open(in_file) as src: #（band\n",
    "        # resample data to target shape\n",
    "        data = src.read(\n",
    "            out_shape=(\n",
    "                src.count,\n",
    "                int(src.height * scale_factor),\n",
    "                int(src.width * scale_factor)\n",
    "            ),\n",
    "            resampling=Resampling.cubic\n",
    "        )\n",
    "\n",
    "        # scale image transform\n",
    "        transform = src.transform * src.transform.scale(\n",
    "            (src.width / data.shape[-1]),\n",
    "            (src.height / data.shape[-2])\n",
    "        )\n",
    "        height = int(src.height * scale_factor)\n",
    "        width = int(src.width * scale_factor)\n",
    "        profile = src.meta.copy()\n",
    "        profile.update({\n",
    "            'driver': 'GTiff',\n",
    "            'height': height,\n",
    "            'width': width,\n",
    "            'transform': transform,\n",
    "        })\n",
    "        with rasterio.open(out_file, 'w', **profile) as dst:\n",
    "            dst.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pci/miniconda3/envs/GeoStats/lib/python3.11/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "for in_file in glob('./Input/RS_LR_x1/*.tif'):\n",
    "    raster_rescale(in_file, in_file.replace('RS_LR_x1', 'RS_LR_x4'), 1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in_file in glob('./Input/RS_LR_x4/*.tif'):\n",
    "    out_file = in_file.replace('.tif', '.png')\n",
    "    !convert {in_file} {out_file}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoStats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
